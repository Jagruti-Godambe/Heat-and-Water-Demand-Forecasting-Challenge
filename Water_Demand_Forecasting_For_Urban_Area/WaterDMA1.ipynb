{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Demand Forecasting Project\n",
    "This notebook performs water demand forecasting using time series data with LSTM-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WaterDMA1 import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining File Paths and Setting Random Seeds\n",
    "File paths for the dataset are defined, and random seeds are set for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WaterDMA_1_Number_of_Meters_path = '/path/to/WaterDMA_1_Number_of_Meters.csv'\n",
    "Training_WaterDMA_1_path = '/path/to/Training_WaterDMA_1.csv'\n",
    "Testing_WaterDMA_1_path = '/path/to/Testing_WaterDMA_1.csv'\n",
    "Weather_data_path = '/path/to/Weather_Bronderslev_20152022.csv'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Preprocessing is performed on the training and testing datasets. Scaling information is also saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro = Water_data_preprocessing(Training_WaterDMA_1_path, WaterDMA_1_Number_of_Meters_path, Weather_data_path)\n",
    "\n",
    "train_data = prepro.fit()\n",
    "test_data = prepro.transform(Testing_WaterDMA_1_path)\n",
    "\n",
    "train_data_scaling_info = train_data[['comsumption', 'meters']]\n",
    "test_data_scaling_info = test_data[['comsumption', 'meters']]\n",
    "\n",
    "train_data = train_data.drop(['comsumption', 'meters'], axis=1)\n",
    "test_data = test_data.drop(['comsumption', 'meters'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "A box plot is created to visualize potential outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(y=train_data['Per_meter_comsumption_with_inter'])\n",
    "plt.title('Box Plot of Per Meter Consumption with Inter')\n",
    "plt.ylabel('Per Meter Consumption')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Calculation\n",
    "Quartiles and IQR (Interquartile Range) are calculated to detect outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 0.00504349748810322, Q3: 0.014305854200097142, IQR: 0.009262356711993922\n",
      "0.028199389268088022\n"
     ]
    }
   ],
   "source": [
    "data = train_data['Per_meter_comsumption_with_inter']\n",
    "Q1 = np.percentile(data, 25)\n",
    "Q3 = np.percentile(data, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
    "print(upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping Outliers\n",
    "The data is clipped to remove outliers beyond the calculated threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "threshold = 0.0281\n",
    "train_data['Per_meter_comsumption_with_inter'] = train_data['Per_meter_comsumption_with_inter'].clip(upper=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequences for LSTM Model\n",
    "We create sequences of data for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31200/31200 [00:02<00:00, 10697.09it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence_length_x = 192\n",
    "sequence_length_y = 24\n",
    "sequences, labels, train_scaling_info = create_sequences(train_data, sequence_length_x, sequence_length_y, train_data_scaling_info)\n",
    "train_X, train_y, train_scale_info, test_X, test_y, test_scale_info = train_test_split(sequences, labels, train_scaling_info, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model Setup\n",
    "We define the model architecture, hyperparameters, and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "input_size = 29\n",
    "sequence_length = 192\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "output_size = 24\n",
    "num_epochs = 500\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "class WaterData(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sequences.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.sequences[idx]), torch.Tensor(self.labels[idx])\n",
    "\n",
    "train_dataloader = DataLoader(WaterData(train_X, train_y), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(WaterData(test_X, test_y), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "The model is trained for the specified number of epochs, and the training and validation losses are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:32<00:00, 15.23it/s]\n"
     ]
    }
   ],
   "source": [
    "list_train_loss = []\n",
    "list_val_loss = []\n",
    "prev_val_loss = 1000\n",
    "epochs = 50\n",
    "for e in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for data, labels in train_dataloader:\n",
    "        data, labels = data.to('mps'), labels.to('mps')\n",
    "        optimizer.zero_grad()\n",
    "        target = model(data)\n",
    "        loss = criterion(target, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    list_train_loss.append(loss.item())\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for data, labels in test_dataloader:\n",
    "        data, labels = data.to('mps'), labels.to('mps')\n",
    "        target = model(data)\n",
    "        val_loss = criterion(target, labels)\n",
    "        valid_loss += val_loss.item()\n",
    "    valid_loss /= len(test_dataloader)\n",
    "    list_val_loss.append(valid_loss)\n",
    "    if prev_val_loss > valid_loss:\n",
    "        prev_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'model_water{e}.pth')\n",
    "    print(f'Epoch {e+1} \\t Training Loss: {loss.item()} \\t Validation Loss: {valid_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Predictions\n",
    "The trained model is evaluated on the test data to generate predictions and calculate performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.015\n",
      "Mean Absolute Percentage Error: 4.5%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_water15.pth'))\n",
    "predictions = predict_inverse(model, test_X)\n",
    "prediction_for_all_meter = pd.DataFrame(test_scale_info[:,:,1]) * predictions\n",
    "mae = mean_absolute_error(test_scale_info[:,:,0], prediction_for_all_meter.to_numpy())\n",
    "mape = mean_absolute_percentage_error(test_scale_info[:,:,0], prediction_for_all_meter.to_numpy())\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error: {mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "The model is used to predict and fill in any missing values in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192, 384, 576, 768, 960, 1152, 1344, 1536]\n"
     ]
    }
   ],
   "source": [
    "def test_pred(model, test_data):\n",
    "    torch.no_grad()\n",
    "    test_data = test_data.reset_index()\n",
    "    idx = test_data[test_data.Per_meter_comsumption_with_inter.isna()].timestamp.dt.date.drop_duplicates(keep='first').index.tolist()\n",
    "    print(idx)\n",
    "    for i in idx:\n",
    "        pre = model(torch.Tensor((test_data.loc[i-192 :i-1]).drop('timestamp', axis=1).values).reshape(1,192,29))\n",
    "        test_data.loc[i:i+23,'Per_meter_comsumption_with_inter'] = pre.detach().numpy().reshape(-1,1)\n",
    "    return test_data\n",
    "\n",
    "preTest = test_pred(model, test_data)\n",
    "preTest = preTest.set_index('timestamp')\n",
    "preTest['Per_meter_comsumption_with_inter'] = preTest['Per_meter_comsumption_with_inter'] * test_data_scaling_info.meters\n",
    "preTest[['Per_meter_comsumption_with_inter']].to_csv('WaterDMA_1.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
