{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Demand Forecasting Project\n",
    "This project involves water demand forecasting using WaterDMA2 data. This notebook walks through data preprocessing, sequence generation, model training using an LSTM model, and final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WaterDMA2 import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining File Paths and Setting Random Seeds\n",
    "We define the file paths for the dataset and set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water data set paths\n",
    "WaterDMA_2_Number_of_Meters_path = '/path/to/WaterDMA_2_Number_of_Meters.csv'\n",
    "Training_WaterDMA_2_path = '/path/to/Training_WaterDMA_2.csv'\n",
    "Testing_WaterDMA_2_path = '/path/to/Testing_WaterDMA_2.csv'\n",
    "Weather_data_path = '/path/to/Weather_Bronderslev_20152022.csv'\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We initialize and run the data preprocessing on the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data preprocessing with file paths\n",
    "prepro = Water_data_preprocessing(Training_WaterDMA_2_path, WaterDMA_2_Number_of_Meters_path, Weather_data_path)\n",
    "\n",
    "# Fit the preprocessing on training data and transform it, then apply the same transformation to testing data\n",
    "train_data = prepro.fit()\n",
    "test_data = prepro.transform(Testing_WaterDMA_2_path)\n",
    "\n",
    "# Extracting and removing scaling information from data\n",
    "train_data_scaling_info = train_data[['comsumption','meters']]\n",
    "test_data_scaling_info = test_data[['comsumption','meters']]\n",
    "train_data = train_data.drop(['comsumption','meters'], axis=1)\n",
    "test_data = test_data.drop(['comsumption','meters'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Generation\n",
    "We create sequences of data to be used as input (X) and labels (y) for the model. The sequence length for input is 192, and for labels, it's 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20232/20232 [00:01<00:00, 12128.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sequence length configuration\n",
    "sequence_length_x = 192\n",
    "sequence_length_y = 24  # Number of future points to predict\n",
    "\n",
    "# Creating sequences and splitting the data into training and testing sets\n",
    "sequences, labels, train_scaling_info = create_sequences(train_data, sequence_length_x, sequence_length_y, train_data_scaling_info)\n",
    "train_X, train_y, train_scale_info, test_X, test_y, test_scale_info = train_test_split(sequences, labels, train_scaling_info, train_size=0.75)\n",
    "\n",
    "# Define a function for inverse prediction\n",
    "def predict_inverse(model, data):\n",
    "    with torch.no_grad():\n",
    "        data = torch.Tensor(data)\n",
    "        prediction = model(data)\n",
    "    return pd.DataFrame(prediction.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "Here we define the model, set hyperparameters, and initialize the dataset and data loaders for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter definition\n",
    "input_size = 23  # Number of features\n",
    "hidden_size = 128\n",
    "num_layers = 5\n",
    "output_size = 24  # Number of future steps to predict\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "\n",
    "# Get the device (CPU or GPU)\n",
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "# Define the custom Dataset class for handling sequences and labels\n",
    "class WaterData(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sequences.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.sequences[idx]), torch.Tensor(self.labels[idx])\n",
    "\n",
    "# Creating data loaders\n",
    "waterData_train = WaterData(train_X, train_y)\n",
    "waterData_val = WaterData(test_X, test_y)\n",
    "train_dataloader = DataLoader(waterData_train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(waterData_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initializing the LSTM model, loss function, and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "This section trains the LSTM model, evaluates it on the validation set, and saves the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "list_train_loss = []\n",
    "list_val_loss = []\n",
    "\n",
    "prev_val_loss = 1000  # Track the best validation loss\n",
    "epochs = 50\n",
    "for e in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for data, labels in train_dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        target = model(data)\n",
    "        loss = criterion(target, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    list_train_loss.append(loss.item())\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    for data, labels in test_dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        target = model(data)\n",
    "        val_loss = criterion(target, labels)\n",
    "        valid_loss += val_loss.item()\n",
    "    valid_loss = valid_loss / len(test_dataloader)\n",
    "    list_val_loss.append(valid_loss)\n",
    "\n",
    "    if prev_val_loss > valid_loss:\n",
    "        prev_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'model_watertest{e}.pth')\n",
    "\n",
    "    print(f'Epoch {e+1} \\t Training Loss: {loss.item()} \\t Validation Loss: {valid_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Prediction\n",
    "We load the trained model and use it to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained LSTM model weights\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "model.load_state_dict(torch.load('model_watertest7.pth'))\n",
    "\n",
    "# Generate predictions\n",
    "predictions = predict_inverse(model, test_X)\n",
    "\n",
    "# Apply inverse scaling\n",
    "prediction_for_all_meter = pd.DataFrame(test_scale_info[:,:,1]) * predictions\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(test_scale_info[:,:,0], prediction_for_all_meter.to_numpy())\n",
    "mape = mean_absolute_percentage_error(test_scale_info[:,:,0], prediction_for_all_meter.to_numpy())\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error: {mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Missing Values\n",
    "Using the trained model, we fill in the missing values in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and fill missing values in the test data using the model.\n",
    "def test_pred(model, test_data):\n",
    "    torch.no_grad()\n",
    "    test_data = test_data.reset_index()\n",
    "    idx = test_data[test_data.Per_meter_comsumption_with_inter.isna()].timestamp.dt.date.drop_duplicates(keep='first').index.tolist()\n",
    "    for i in idx:\n",
    "        pre = model(torch.Tensor((test_data.loc[i-192:i-1]).drop('timestamp', axis=1).values).reshape(1,192,23))\n",
    "        test_data.loc[i:i+23,'Per_meter_comsumption_with_inter'] = pre.detach().numpy().reshape(-1,1)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "preTest = test_pred(model, test_data)\n",
    "preTest = preTest.set_index('timestamp')\n",
    "\n",
    "# Calculate original consumption value from per meter consumption and number of meters\n",
    "preTest['Per_meter_comsumption_with_inter'] = preTest['Per_meter_comsumption_with_inter'] * test_data_scaling_info.meters\n",
    "\n",
    "# Store results in CSV\n",
    "preTest[['Per_meter_comsumption_with_inter']].to_csv('WaterDMA_2.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
