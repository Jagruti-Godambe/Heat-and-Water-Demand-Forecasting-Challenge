{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WaterDMA2 import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sns.set()\n",
    "\n",
    "# Water data set paths\n",
    "WaterDMA_2_Number_of_Meters_path = '/Users/jagrutigodambe/Desktop/Data/water/WaterDMA_2_Number_of_Meters.csv'\n",
    "Training_WaterDMA_2_path = '/Users/jagrutigodambe/Desktop/Data/water/Training_WaterDMA_2.csv'\n",
    "Testing_WaterDMA_2_path = '/Users/jagrutigodambe/Desktop/Data/water/Testing_WaterDMA_2.csv'\n",
    "Weather_data_path = '/Users/jagrutigodambe/Desktop/Data/weather/Weather_Bronderslev_20152022.csv'\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data preprocessing with file paths\n",
    "prepro = Water_data_preprocessing(Training_WaterDMA_2_path,\n",
    "                        WaterDMA_2_Number_of_Meters_path,\n",
    "                        Weather_data_path)\n",
    "\n",
    "# Fit the preprocessing on training data and transform it, then apply the same transformation to testing data\n",
    "train_data = prepro.fit()\n",
    "test_data = prepro.transform(Testing_WaterDMA_2_path)\n",
    "\n",
    "train_data_scaling_info = train_data[['comsumption','meters']]\n",
    "test_data_scaling_info = test_data[['comsumption','meters']]\n",
    "\n",
    "train_data = train_data.drop(['comsumption','meters'], axis=1)\n",
    "test_data = test_data.drop(['comsumption','meters'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20232/20232 [00:01<00:00, 12128.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create sequences of 192 entries to predict the next 24 entries\n",
    "\n",
    "sequence_length_x = 192\n",
    "sequence_length_y = 24 # y is label\n",
    "sequences, labels , train_scaling_info  = create_sequences(train_data, sequence_length_x, sequence_length_y, train_data_scaling_info)\n",
    "train_X, train_y, train_scale_info, test_X, test_y, test_scale_info = train_test_split(sequences, labels , train_scaling_info, train_size = 0.75)\n",
    "\n",
    "\n",
    "def predict_inverse(model ,data):#, scaling_info):\n",
    "    with torch.no_grad():\n",
    "       data = torch.Tensor(data)\n",
    "       prediction = model(data)\n",
    "    return pd.DataFrame(prediction.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters, create data loaders, and initialize the model and optimizer\n",
    "input_size = 23  # Feature dimension\n",
    "sequence_length = 192\n",
    "\n",
    "hidden_size = 128\n",
    "num_layers = 5\n",
    "\n",
    "output_size = 24\n",
    "\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "\n",
    "class HeatData(Dataset):\n",
    "\n",
    "    def __init__(self, sequences, labels):\n",
    "      self.sequences = sequences\n",
    "      self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.sequences.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      return torch.Tensor(self.sequences[idx]), torch.Tensor(self.labels[idx])\n",
    "\n",
    "\n",
    "heatData_train = HeatData(train_X, train_y)\n",
    "heatData_val = HeatData(test_X, test_y)\n",
    "\n",
    "train_dataloader = DataLoader(heatData_train, batch_size=batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(heatData_val, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "list_train_loss = []\n",
    "list_val_loss = []\n",
    "\n",
    "prev_val_loss = 1000\n",
    "epochs = 50\n",
    "for e in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for data, labels in train_dataloader:\n",
    "        # Transfer Data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = model(data)\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "    list_train_loss.append(loss.item())\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in test_dataloader:\n",
    "        # Transfer Data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        # Forward Pass\n",
    "        target = model(data)\n",
    "        # Find the Loss\n",
    "        val_loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += val_loss.item()\n",
    "    valid_loss =  valid_loss/len(test_dataloader)\n",
    "    list_val_loss.append(valid_loss)\n",
    "\n",
    "    if prev_val_loss > valid_loss:\n",
    "        # updating loss\n",
    "        prev_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model_watertest{}.pth'.format(e))\n",
    "\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: { loss.item()} \\t\\t Validation Loss: { valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained LSTM model weights\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "model.load_state_dict(torch.load('model_water{}.pth'.format(7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.93383428786942"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions = predict_inverse(model, test_X)\n",
    "\n",
    "prediction_for_all_meter = pd.DataFrame(test_scale_info[:,:,1]) * predictions\n",
    "\n",
    "mean_absolute_percentage_error(test_scale_info[:,:,0],prediction_for_all_meter.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5638536555297279"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions and calculate MAE and MAPE.\n",
    "predictions = predict_inverse(model, test_X)\n",
    "prediction_for_all_meter = pd.DataFrame(test_scale_info[:,:,1]) * predictions\n",
    "\n",
    "mean_absolute_error(test_scale_info[:,:,0],prediction_for_all_meter.to_numpy())\n",
    "mean_absolute_percentage_error(test_scale_info[:,:,0],prediction_for_all_meter.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and fill missing values in the test data using the model.\n",
    "def test_pred(model, test_data):\n",
    "    torch.no_grad()\n",
    "    test_data = test_data.reset_index()\n",
    "    \n",
    "    idx = test_data[test_data.Per_meter_comsumption_with_inter.isna()].timestamp.dt.date.drop_duplicates(keep='first').index.tolist()\n",
    "    print(idx)\n",
    "    for i in idx:\n",
    "        pre = model(torch.Tensor((test_data.loc[i-192\n",
    "              :i-1]).drop('timestamp', axis=1).values).reshape(1,192,23))\n",
    "       #print((pre.detach().numpy().reshape(-1,1)))\n",
    "        #print(len(test_data.loc[i :i+23,'Per_meter_comsumption_with_inter']))\n",
    "        test_data.loc[i :i+23,'Per_meter_comsumption_with_inter'] = pre.detach().numpy().reshape(-1,1)\n",
    "    \n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192, 384, 576, 768, 960, 1152, 1344, 1536, 1728, 1920, 2112, 2304, 2496, 2688, 2880, 3072, 3264, 3456, 3648, 3840]\n"
     ]
    }
   ],
   "source": [
    "preTest = test_pred(model, test_data)\n",
    "preTest= preTest.set_index('timestamp')\n",
    "# Calculating original consumption value from per meter consumption and number of meters\n",
    "preTest.Per_meter_comsumption_with_inter  = preTest.Per_meter_comsumption_with_inter * test_data_scaling_info.meters\n",
    "# Storing results in CSV\n",
    "preTest[['Per_meter_comsumption_with_inter']].to_csv('WaterDMA_2.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
